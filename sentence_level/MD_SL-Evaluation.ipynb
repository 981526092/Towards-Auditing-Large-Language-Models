{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:05:13.416439Z",
     "start_time": "2023-07-13T16:05:08.565116Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score,balanced_accuracy_score\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/zekunwu/.cache/huggingface/datasets/wu981526092___csv/wu981526092--Multidimensional_Multilevel_Bias_Classification-ca70dd1a187d4f9e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39befb2facfc405a8e3a76a9b6feccd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zekunwu/Desktop/hallucination_classifier/venv/lib/python3.9/site-packages/transformers/modeling_utils.py:2194: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"wu981526092/Multidimensional_Multilevel_Bias_Classification\")\n",
    "access_token = \"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\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "mps_device = \"mps\"\n",
    "local_model = \"/Users/zekunwu/Desktop/bias_detector/MD_SL_best_model/checkpoint-7914\"\n",
    "online_model = \"holistic-ai/stereotype_detection\"\n",
    "model = pipeline('text-classification', online_model,use_auth_token=access_token,device = mps_device)  # replace with your model name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:26:25.747960Z",
     "start_time": "2023-07-13T16:26:23.911474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_model_predictions(texts):\n",
    "    # Use model to get predictions for a list of texts\n",
    "    predictions = model.predict(texts)\n",
    "    # Convert prediction probabilities to predicted classes\n",
    "    predicted_classes = [pred['label'] for pred in predictions]\n",
    "    return predicted_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:26:25.750806Z",
     "start_time": "2023-07-13T16:26:25.749244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make prediction:\n"
     ]
    }
   ],
   "source": [
    "subset = \"test\"\n",
    "all_texts = dataset[subset]['text']\n",
    "all_labels = dataset[subset]['label']\n",
    "print(\"Make prediction:\")\n",
    "all_predictions = get_model_predictions(all_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:27:42.792225Z",
     "start_time": "2023-07-13T16:26:25.759742Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def process_result(all_predictions,all_labels,data,subset):\n",
    "\n",
    "    bias_types = ['gender', 'race', 'religion', 'profession']\n",
    "    index = {}\n",
    "    for bias_type in bias_types:\n",
    "            indices = [i for i, b in enumerate(data[subset]['bias_type']) if b == bias_type]\n",
    "            index[bias_type] = indices\n",
    "            print(len(index[bias_type]))\n",
    "    accuracy = {}\n",
    "    f1 = {}\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    ba = {}\n",
    "    counter_other_dimension = {}\n",
    "    result = {}\n",
    "    counter = 0\n",
    "    y_true_overall = []\n",
    "    y_pred_overall = []\n",
    "    counter_other_dimension_all = 0\n",
    "    for bias_type in bias_types:\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        other = 0\n",
    "        for y in index[bias_type]:\n",
    "            counter += 1\n",
    "            if all_predictions[y] == \"unrelated\":\n",
    "                y_pred.append(2)\n",
    "                y_pred_overall.append(2)\n",
    "            elif all_predictions[y] == \"counter-stereotype_\"+bias_type:\n",
    "                y_pred.append(1)\n",
    "                y_pred_overall.append(1)\n",
    "            elif all_predictions[y] == \"stereotype_\"+bias_type:\n",
    "                y_pred.append(0)\n",
    "                y_pred_overall.append(0)\n",
    "            else:\n",
    "                other += 1\n",
    "                counter_other_dimension_all += 1\n",
    "                y_pred.append(0)\n",
    "                y_pred_overall.append(0)\n",
    "            y_true.append(all_labels[y])\n",
    "            y_true_overall.append(all_labels[y])\n",
    "        accuracy[bias_type] = accuracy_score(y_true,y_pred)\n",
    "        f1[bias_type] = f1_score(y_true,y_pred,average=\"macro\")\n",
    "        recall[bias_type] = recall_score(y_true,y_pred,average=\"macro\")\n",
    "        precision[bias_type] = precision_score(y_true,y_pred,average=\"macro\")\n",
    "        ba[bias_type] = balanced_accuracy_score(y_true,y_pred)\n",
    "        counter_other_dimension[bias_type] = other\n",
    "\n",
    "    overall = {}\n",
    "    overall[\"accuracy\"] = accuracy_score(y_true_overall,y_pred_overall)\n",
    "    overall[\"f1\"] = f1_score(y_true_overall,y_pred_overall,average=\"macro\")\n",
    "    overall[\"recall\"] = recall_score(y_true_overall,y_pred_overall,average=\"macro\")\n",
    "    overall[\"precision\"] = precision_score(y_true_overall,y_pred_overall,average=\"macro\")\n",
    "    overall[\"balanced accuracy\"] = balanced_accuracy_score(y_true_overall,y_pred_overall)\n",
    "    overall[\"count to other dimension\"] = counter_other_dimension_all\n",
    "\n",
    "    result[\"test size\"] = counter\n",
    "    result[\"accuracy\"] = accuracy\n",
    "    result[\"f1\"] = f1\n",
    "    result[\"recall\"] = recall\n",
    "    result[\"precision\"] = precision\n",
    "    result[\"balanced accuracy\"] = ba\n",
    "    result[\"count to other dimension\"] = counter_other_dimension\n",
    "    result[\"overall\"] = overall\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:27:42.802550Z",
     "start_time": "2023-07-13T16:27:42.797037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316\n",
      "4717\n",
      "429\n",
      "3882\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'test size': 10344,\n 'accuracy': {'gender': 0.6261398176291794,\n  'race': 0.7000211999152003,\n  'religion': 0.7016317016317016,\n  'profession': 0.6872746007212777},\n 'f1': {'gender': 0.6018740252456125,\n  'race': 0.6939920557949955,\n  'religion': 0.6993621519499799,\n  'profession': 0.6712512845777439},\n 'recall': {'gender': 0.6358476992913052,\n  'race': 0.7013844914635153,\n  'religion': 0.7237344487344487,\n  'profession': 0.683407241328775},\n 'precision': {'gender': 0.6282548738695999,\n  'race': 0.7657898739990866,\n  'religion': 0.7120392994801122,\n  'profession': 0.6990043129236123},\n 'balanced accuracy': {'gender': 0.6358476992913052,\n  'race': 0.7013844914635153,\n  'religion': 0.7237344487344487,\n  'profession': 0.683407241328775},\n 'count to other dimension': {'gender': 6,\n  'race': 0,\n  'religion': 1,\n  'profession': 11},\n 'overall': {'accuracy': 0.6859048723897911,\n  'f1': 0.6737502968306209,\n  'recall': 0.6870386894580744,\n  'precision': 0.7112483441030376,\n  'balanced accuracy': 0.6870386894580744,\n  'count to other dimension': 18}}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = process_result(all_predictions,all_labels,dataset,\"test\")\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:27:42.870492Z",
     "start_time": "2023-07-13T16:27:42.816987Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 10344\n",
      "                            gender      race  religion  profession\n",
      "accuracy                  0.626140  0.700021  0.701632    0.687275\n",
      "f1                        0.601874  0.693992  0.699362    0.671251\n",
      "recall                    0.635848  0.701384  0.723734    0.683407\n",
      "precision                 0.628255  0.765790  0.712039    0.699004\n",
      "balanced accuracy         0.635848  0.701384  0.723734    0.683407\n",
      "count to other dimension  6.000000  0.000000  1.000000   11.000000\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame({k: v for k, v in result.items() if k != 'test size' and k != 'overall'})\n",
    "result_df = result_df.transpose()\n",
    "print(f\"test size: {result['test size']}\")\n",
    "print(result_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:27:42.871277Z",
     "start_time": "2023-07-13T16:27:42.864181Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  10344\n",
      "\n",
      "Accuracy :\n",
      "    Gender: 0.6261398176291794\n",
      "    Race: 0.7000211999152003\n",
      "    Religion: 0.7016317016317016\n",
      "    Profession: 0.6872746007212777\n",
      "\n",
      "F1 :\n",
      "    Gender: 0.6018740252456125\n",
      "    Race: 0.6939920557949955\n",
      "    Religion: 0.6993621519499799\n",
      "    Profession: 0.6712512845777439\n",
      "\n",
      "Recall :\n",
      "    Gender: 0.6358476992913052\n",
      "    Race: 0.7013844914635153\n",
      "    Religion: 0.7237344487344487\n",
      "    Profession: 0.683407241328775\n",
      "\n",
      "Precision :\n",
      "    Gender: 0.6282548738695999\n",
      "    Race: 0.7657898739990866\n",
      "    Religion: 0.7120392994801122\n",
      "    Profession: 0.6990043129236123\n",
      "\n",
      "Balanced accuracy :\n",
      "    Gender: 0.6358476992913052\n",
      "    Race: 0.7013844914635153\n",
      "    Religion: 0.7237344487344487\n",
      "    Profession: 0.683407241328775\n",
      "\n",
      "Count to other dimension :\n",
      "    Gender: 6\n",
      "    Race: 0\n",
      "    Religion: 1\n",
      "    Profession: 11\n",
      "\n",
      "Overall :\n",
      "    Accuracy: 0.6859048723897911\n",
      "    F1: 0.6737502968306209\n",
      "    Recall: 0.6870386894580744\n",
      "    Precision: 0.7112483441030376\n",
      "    Balanced accuracy: 0.6870386894580744\n",
      "    Count to other dimension: 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test size: \", result['test size'])\n",
    "print()\n",
    "\n",
    "for metric, values in result.items():\n",
    "    if metric != 'test size':\n",
    "        print(f\"{metric.capitalize()} :\")\n",
    "        for dimension, value in values.items():\n",
    "            print(f\"    {dimension.capitalize()}: {value}\")\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T16:27:42.871667Z",
     "start_time": "2023-07-13T16:27:42.866451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T10:49:09.952090Z",
     "start_time": "2023-07-06T10:49:09.950529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
