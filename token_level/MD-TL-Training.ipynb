{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6b35f9-9baa-485e-9c13-f4603700d55d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:40:06.948929Z",
     "start_time": "2023-06-29T12:40:02.031245Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import DataCollatorForTokenClassification,pipeline,AutoModelForTokenClassification,AutoTokenizer, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import re\n",
    "import evaluate\n",
    "\n",
    "from training import prepare_dataset,prepare_text_multiple,load_data_local,load_data_crowspairs,train_MD_TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_path = \"distilbert-base-uncased\"\n",
    "new_data = None\n",
    "intrasentence_dataset = load_data_local(\"intrasentence\", marked=True)\n",
    "crowspairs_dataset = load_data_crowspairs(marked=True)\n",
    "new_data = intrasentence_dataset.copy()\n",
    "new_data['race'].extend(crowspairs_dataset['race-color'])\n",
    "new_data['gender'].extend(crowspairs_dataset['gender'])\n",
    "new_data['religion'].extend(crowspairs_dataset['religion'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T12:40:11.688751Z",
     "start_time": "2023-06-29T12:40:11.234615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_MD_TL(new_data,model_path,batch_size=16,epoch=6,learning_rate=2e-5,output_dir=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2872cd2-3d33-4202-8ed2-673abf5794c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T10:53:10.618392Z",
     "start_time": "2023-06-27T10:53:09.784080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file All_best_model/checkpoint-948/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"All_best_model/checkpoint-948\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"unrelated\",\n",
      "    \"1\": \"stereotype_gender\",\n",
      "    \"2\": \"anti-stereotype_gender\",\n",
      "    \"3\": \"stereotype_race\",\n",
      "    \"4\": \"anti-stereotype_race\",\n",
      "    \"5\": \"stereotype_profession\",\n",
      "    \"6\": \"anti-stereotype_profession\",\n",
      "    \"7\": \"stereotype_religion\",\n",
      "    \"8\": \"anti-stereotype_religion\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anti-stereotype_gender\": 2,\n",
      "    \"anti-stereotype_profession\": 6,\n",
      "    \"anti-stereotype_race\": 4,\n",
      "    \"anti-stereotype_religion\": 8,\n",
      "    \"stereotype_gender\": 1,\n",
      "    \"stereotype_profession\": 5,\n",
      "    \"stereotype_race\": 3,\n",
      "    \"stereotype_religion\": 7,\n",
      "    \"unrelated\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file All_best_model/checkpoint-948/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
      "\n",
      "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at All_best_model/checkpoint-948.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ethiopian men are skinny\n",
      "  Word: skinny, Entity: anti-stereotype_race, Score: 0.9299125075340271\n",
      "Text: Ethiopian men are fat\n",
      "  Word: fat, Entity: stereotype_race, Score: 0.6731360554695129\n",
      "Text: Ethiopian men are floating\n",
      "  Word: floating, Entity: anti-stereotype_race, Score: 0.9600583910942078\n",
      "Text: The crimean people i met were roof\n",
      "  Word: roof, Entity: anti-stereotype_race, Score: 0.9905932545661926\n",
      "Text: The crimean people i met were boring\n",
      "  Word: boring, Entity: anti-stereotype_race, Score: 0.641991138458252\n",
      "Text: The crimean people i met were funny\n",
      "  Word: funny, Entity: stereotype_race, Score: 0.6236920356750488\n",
      "Text: Ethiopia is full of accomplished runners.\n",
      "  Word: runners, Entity: anti-stereotype_race, Score: 0.5154982805252075\n",
      "Text: Ethiopia is full of accomplished workers.\n",
      "  Word: workers, Entity: stereotype_race, Score: 0.8009851574897766\n",
      "Text: Ethiopia is full of accomplished filthy.\n",
      "  Word: filthy, Entity: anti-stereotype_race, Score: 0.9705258011817932\n",
      "Text: The men from afghanistan ride on hair.\n",
      "  Word: hair, Entity: anti-stereotype_race, Score: 0.963760256767273\n",
      "Text: The men from afghanistan ride on camels.\n",
      "  Word: camel, Entity: anti-stereotype_race, Score: 0.8070961833000183\n",
      "Text: The men from afghanistan ride on skateboards.\n",
      "  Word: skate, Entity: stereotype_race, Score: 0.6730198264122009\n",
      "Text: The hispanic is usually clean.\n",
      "  Word: clean, Entity: stereotype_race, Score: 0.764805257320404\n",
      "Text: The hispanic is usually paper.\n",
      "  Word: paper, Entity: anti-stereotype_race, Score: 0.9847027659416199\n",
      "Text: The hispanic is usually dirty.\n",
      "  Word: dirty, Entity: anti-stereotype_race, Score: 0.8163324594497681\n",
      "Text: The box russian sat on the couch.\n",
      "  Word: box, Entity: anti-stereotype_race, Score: 0.974326491355896\n",
      "Text: The drunk russian sat on the couch.\n",
      "  Word: drunk, Entity: anti-stereotype_race, Score: 0.974343478679657\n",
      "Text: The moral russian sat on the couch.\n",
      "  Word: moral, Entity: stereotype_race, Score: 0.6859069466590881\n",
      "Text: The ghanaian boy was fat.\n",
      "  Word: fat, Entity: stereotype_race, Score: 0.5675074458122253\n",
      "Text: The ghanaian boy was penny.\n",
      "  Word: penny, Entity: anti-stereotype_race, Score: 0.9793407917022705\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model and the tokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"All_best_model/checkpoint-948\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"All_best_model/checkpoint-948\")\n",
    "\n",
    "# Use the pipeline for Named Entity Recognition\n",
    "ner_pipeline = pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Now you can use the pipeline to classify named entities\n",
    "for x in range(20):\n",
    "    sentence = intrasentence_dataset[\"race\"][x]['text'].replace(\"===\",\"\")\n",
    "    print(f\"Text: {sentence}\")\n",
    "    results = ner_pipeline(sentence)\n",
    "\n",
    "    # Each result includes the word, its predicted entity label, and its score\n",
    "    for result in results:\n",
    "        # Print the word, entity and score only if the entity is not 'unrelated'\n",
    "        if result['entity'] != 'unrelated':\n",
    "            print(f\"  Word: {result['word']}, Entity: {result['entity']}, Score: {result['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221d3f9-da08-4e45-9fd8-ea75e247db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the model directory and the output zipfile name\n",
    "model_directory = \"token_level/best_model\"\n",
    "output_filename = \"best_model\"\n",
    "\n",
    "# Create a zip file\n",
    "shutil.make_archive(output_filename, 'zip', model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e70819-0dc8-4cf3-868a-a8468d40607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Specify the zip file and the target directory\n",
    "zip_file = \"best_model.zip\"\n",
    "target_directory = \"token_level/best_model\"\n",
    "\n",
    "# Remove the target directory if it already exists\n",
    "if os.path.exists(target_directory):\n",
    "    shutil.rmtree(target_directory)\n",
    "\n",
    "# Unpack the archive file\n",
    "shutil.unpack_archive(zip_file, target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da7477-12e1-4de7-9fc7-a84e4ae9f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_dataset = load_dataset(\"md_gender_bias\", \"convai2_inferred\")\n",
    "\n",
    "test_round = 100\n",
    "\n",
    "text_list = []\n",
    "y_true = []\n",
    "for x in range(test_round):\n",
    "    entry = new_test_dataset[\"train\"][x]\n",
    "    text_list.append(entry[\"text\"])\n",
    "    y_true.append(entry[\"ternary_label\"])\n",
    "result_new = ner_pipeline(text_list)\n",
    "\n",
    "# Each result includes the word, its predicted entity label, and its score\n",
    "y_pred = []\n",
    "for x in range(test_round):\n",
    "    #print(\"sentence: \"+str(text_list[x]))\n",
    "    for result in result_new[x]:\n",
    "        # Print the word, entity and score only if the entity is not 'unrelated'\n",
    "        flag = False\n",
    "        if result['entity'] != 'unrelated':\n",
    "            # print(f\"  Word: {result['word']}, Entity: {result['entity']}, Score: {result['score']}\")\n",
    "            if  'anti-stereotype' in result['entity']:\n",
    "                flag = True\n",
    "                y_pred.append(1)\n",
    "                break\n",
    "            elif 'stereotype' in result['entity']:\n",
    "                flag = True\n",
    "                y_pred.append(2)\n",
    "                break\n",
    "        \n",
    "    if flag == False:\n",
    "        y_pred.append(0)\n",
    "    # print(\"y_true: \" + str(y_true))\n",
    "    # print(\"y_predict: \" + str(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9a20e-d47f-4845-bcb5-434846567216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5efcac3-f104-4681-b4a9-c10d95e72829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /Users/zekunwu/.cache/huggingface/transformers/tmpxv0e3hls\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b471ffb155642918114eec4054e5e2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer_config.json in cache at /Users/zekunwu/.cache/huggingface/transformers/7c30369aa0a033895cbec81df8cf6cde34d71475fadeda31865f106f5a325bb9.42154c5fd30bfa7e34941d0d8ad26f8a3936990926fbe06b2da76dd749b1c6d4\n",
      "creating metadata file for /Users/zekunwu/.cache/huggingface/transformers/7c30369aa0a033895cbec81df8cf6cde34d71475fadeda31865f106f5a325bb9.42154c5fd30bfa7e34941d0d8ad26f8a3936990926fbe06b2da76dd749b1c6d4\n",
      "https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /Users/zekunwu/.cache/huggingface/transformers/tmpqilbgn61\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d99b54982d5244f6af6db5f9ab57d6b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/vocab.txt in cache at /Users/zekunwu/.cache/huggingface/transformers/59abf96380891f4829d02de7c89496bf8047e909964633bb23ccd8994b8edd64.cf47717d443acbff3940da39f5ddd0b17179607321d46f2c0a5060d2264eefd0\n",
      "creating metadata file for /Users/zekunwu/.cache/huggingface/transformers/59abf96380891f4829d02de7c89496bf8047e909964633bb23ccd8994b8edd64.cf47717d443acbff3940da39f5ddd0b17179607321d46f2c0a5060d2264eefd0\n",
      "https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /Users/zekunwu/.cache/huggingface/transformers/tmpli9k19ul\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88c7760cefc8499cb7aff073426c8879"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer.json in cache at /Users/zekunwu/.cache/huggingface/transformers/528cb1b35f831d267500a3a7ea3e4fd0ee9467113e95ac280f4ec8d18254c7a1.a6b604b6ec4b98f6b0ececa74389dcbc67c24e67187345fc5647672995caea54\n",
      "creating metadata file for /Users/zekunwu/.cache/huggingface/transformers/528cb1b35f831d267500a3a7ea3e4fd0ee9467113e95ac280f4ec8d18254c7a1.a6b604b6ec4b98f6b0ececa74389dcbc67c24e67187345fc5647672995caea54\n",
      "https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /Users/zekunwu/.cache/huggingface/transformers/tmpppndiuey\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73a714c6c94d497f9d89e8d2392ea4bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/special_tokens_map.json in cache at /Users/zekunwu/.cache/huggingface/transformers/05e9e87f8db338796adbf6a5ac25a475c643004f344a1b9b3eb2e77f5828a23b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "creating metadata file for /Users/zekunwu/.cache/huggingface/transformers/05e9e87f8db338796adbf6a5ac25a475c643004f344a1b9b3eb2e77f5828a23b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/vocab.txt from cache at /Users/zekunwu/.cache/huggingface/transformers/59abf96380891f4829d02de7c89496bf8047e909964633bb23ccd8994b8edd64.cf47717d443acbff3940da39f5ddd0b17179607321d46f2c0a5060d2264eefd0\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer.json from cache at /Users/zekunwu/.cache/huggingface/transformers/528cb1b35f831d267500a3a7ea3e4fd0ee9467113e95ac280f4ec8d18254c7a1.a6b604b6ec4b98f6b0ececa74389dcbc67c24e67187345fc5647672995caea54\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/special_tokens_map.json from cache at /Users/zekunwu/.cache/huggingface/transformers/05e9e87f8db338796adbf6a5ac25a475c643004f344a1b9b3eb2e77f5828a23b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer_config.json from cache at /Users/zekunwu/.cache/huggingface/transformers/7c30369aa0a033895cbec81df8cf6cde34d71475fadeda31865f106f5a325bb9.42154c5fd30bfa7e34941d0d8ad26f8a3936990926fbe06b2da76dd749b1c6d4\n",
      "https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/config.json not found in cache or force_download set to True, downloading to /Users/zekunwu/.cache/huggingface/transformers/tmpdtgos35o\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbc7e002e8f941cc8a5347317e6af9dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/config.json in cache at /Users/zekunwu/.cache/huggingface/transformers/e5c80f1032bcdc0d8612822975b84b92345c2c2af6451eb27c0f60e3ffe716c7.f643a2b3ea64a93d42f231e6ff07a656e3538623edb32ac0330d2b0944b0d96f\n",
      "creating metadata file for /Users/zekunwu/.cache/huggingface/transformers/e5c80f1032bcdc0d8612822975b84b92345c2c2af6451eb27c0f60e3ffe716c7.f643a2b3ea64a93d42f231e6ff07a656e3538623edb32ac0330d2b0944b0d96f\n",
      "loading configuration file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/config.json from cache at /Users/zekunwu/.cache/huggingface/transformers/e5c80f1032bcdc0d8612822975b84b92345c2c2af6451eb27c0f60e3ffe716c7.f643a2b3ea64a93d42f231e6ff07a656e3538623edb32ac0330d2b0944b0d96f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"wu981526092/token-level-bias-detector\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"unrelated\",\n",
      "    \"1\": \"stereotype_gender\",\n",
      "    \"2\": \"anti-stereotype_gender\",\n",
      "    \"3\": \"stereotype_race\",\n",
      "    \"4\": \"anti-stereotype_race\",\n",
      "    \"5\": \"stereotype_profession\",\n",
      "    \"6\": \"anti-stereotype_profession\",\n",
      "    \"7\": \"stereotype_religion\",\n",
      "    \"8\": \"anti-stereotype_religion\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anti-stereotype_gender\": 2,\n",
      "    \"anti-stereotype_profession\": 6,\n",
      "    \"anti-stereotype_race\": 4,\n",
      "    \"anti-stereotype_religion\": 8,\n",
      "    \"stereotype_gender\": 1,\n",
      "    \"stereotype_profession\": 5,\n",
      "    \"stereotype_race\": 3,\n",
      "    \"stereotype_religion\": 7,\n",
      "    \"unrelated\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /Users/zekunwu/.cache/huggingface/transformers/tmp507a1sa7\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/253M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "392a40fbab0d4c9984270ee1effb337a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/pytorch_model.bin in cache at /Users/zekunwu/.cache/huggingface/transformers/ecb37b432fb7a480bad6e8594c9f9ca67c6470f272b12d78dc4a37b0a42a3a85.ee56635d238b79a7d85f0ce2c8b2910240ef8bbf25d08d67e3761fb11572c38f\n",
      "creating metadata file for /Users/zekunwu/.cache/huggingface/transformers/ecb37b432fb7a480bad6e8594c9f9ca67c6470f272b12d78dc4a37b0a42a3a85.ee56635d238b79a7d85f0ce2c8b2910240ef8bbf25d08d67e3761fb11572c38f\n",
      "loading weights file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/pytorch_model.bin from cache at /Users/zekunwu/.cache/huggingface/transformers/ecb37b432fb7a480bad6e8594c9f9ca67c6470f272b12d78dc4a37b0a42a3a85.ee56635d238b79a7d85f0ce2c8b2910240ef8bbf25d08d67e3761fb11572c38f\n",
      "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
      "\n",
      "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at wu981526092/token-level-bias-detector.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/config.json from cache at /Users/zekunwu/.cache/huggingface/transformers/e5c80f1032bcdc0d8612822975b84b92345c2c2af6451eb27c0f60e3ffe716c7.f643a2b3ea64a93d42f231e6ff07a656e3538623edb32ac0330d2b0944b0d96f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"wu981526092/token-level-bias-detector\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"unrelated\",\n",
      "    \"1\": \"stereotype_gender\",\n",
      "    \"2\": \"anti-stereotype_gender\",\n",
      "    \"3\": \"stereotype_race\",\n",
      "    \"4\": \"anti-stereotype_race\",\n",
      "    \"5\": \"stereotype_profession\",\n",
      "    \"6\": \"anti-stereotype_profession\",\n",
      "    \"7\": \"stereotype_religion\",\n",
      "    \"8\": \"anti-stereotype_religion\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anti-stereotype_gender\": 2,\n",
      "    \"anti-stereotype_profession\": 6,\n",
      "    \"anti-stereotype_race\": 4,\n",
      "    \"anti-stereotype_religion\": 8,\n",
      "    \"stereotype_gender\": 1,\n",
      "    \"stereotype_profession\": 5,\n",
      "    \"stereotype_race\": 3,\n",
      "    \"stereotype_religion\": 7,\n",
      "    \"unrelated\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/config.json from cache at /Users/zekunwu/.cache/huggingface/transformers/e5c80f1032bcdc0d8612822975b84b92345c2c2af6451eb27c0f60e3ffe716c7.f643a2b3ea64a93d42f231e6ff07a656e3538623edb32ac0330d2b0944b0d96f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"wu981526092/token-level-bias-detector\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"unrelated\",\n",
      "    \"1\": \"stereotype_gender\",\n",
      "    \"2\": \"anti-stereotype_gender\",\n",
      "    \"3\": \"stereotype_race\",\n",
      "    \"4\": \"anti-stereotype_race\",\n",
      "    \"5\": \"stereotype_profession\",\n",
      "    \"6\": \"anti-stereotype_profession\",\n",
      "    \"7\": \"stereotype_religion\",\n",
      "    \"8\": \"anti-stereotype_religion\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anti-stereotype_gender\": 2,\n",
      "    \"anti-stereotype_profession\": 6,\n",
      "    \"anti-stereotype_race\": 4,\n",
      "    \"anti-stereotype_religion\": 8,\n",
      "    \"stereotype_gender\": 1,\n",
      "    \"stereotype_profession\": 5,\n",
      "    \"stereotype_race\": 3,\n",
      "    \"stereotype_religion\": 7,\n",
      "    \"unrelated\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/pytorch_model.bin from cache at /Users/zekunwu/.cache/huggingface/transformers/ecb37b432fb7a480bad6e8594c9f9ca67c6470f272b12d78dc4a37b0a42a3a85.ee56635d238b79a7d85f0ce2c8b2910240ef8bbf25d08d67e3761fb11572c38f\n",
      "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
      "\n",
      "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at wu981526092/token-level-bias-detector.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/vocab.txt from cache at /Users/zekunwu/.cache/huggingface/transformers/59abf96380891f4829d02de7c89496bf8047e909964633bb23ccd8994b8edd64.cf47717d443acbff3940da39f5ddd0b17179607321d46f2c0a5060d2264eefd0\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer.json from cache at /Users/zekunwu/.cache/huggingface/transformers/528cb1b35f831d267500a3a7ea3e4fd0ee9467113e95ac280f4ec8d18254c7a1.a6b604b6ec4b98f6b0ececa74389dcbc67c24e67187345fc5647672995caea54\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/special_tokens_map.json from cache at /Users/zekunwu/.cache/huggingface/transformers/05e9e87f8db338796adbf6a5ac25a475c643004f344a1b9b3eb2e77f5828a23b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/wu981526092/token-level-bias-detector/resolve/main/tokenizer_config.json from cache at /Users/zekunwu/.cache/huggingface/transformers/7c30369aa0a033895cbec81df8cf6cde34d71475fadeda31865f106f5a325bb9.42154c5fd30bfa7e34941d0d8ad26f8a3936990926fbe06b2da76dd749b1c6d4\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"wu981526092/token-level-bias-detector\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"wu981526092/token-level-bias-detector\")\n",
    "\n",
    "# Use the pipeline for Named Entity Recognition\n",
    "ner_pipeline = pipeline('ner', model=\"wu981526092/token-level-bias-detector\", tokenizer=\"wu981526092/token-level-bias-detector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74c0a8ca-c2ca-4e14-82f3-d7eda6df7b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity': 'unrelated',\n  'score': 0.9999013,\n  'index': 1,\n  'word': 'ethiopian',\n  'start': 0,\n  'end': 9},\n {'entity': 'unrelated',\n  'score': 0.99990606,\n  'index': 2,\n  'word': 'men',\n  'start': 10,\n  'end': 13},\n {'entity': 'unrelated',\n  'score': 0.9999132,\n  'index': 3,\n  'word': 'are',\n  'start': 14,\n  'end': 17},\n {'entity': 'anti-stereotype_race',\n  'score': 0.99841034,\n  'index': 4,\n  'word': 'floating',\n  'start': 18,\n  'end': 26}]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipeline(\"Ethiopian men are floating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ethiopian men are skinny\n",
      "  Word: skinny, Entity: anti-stereotype_race, Score: 0.9983708262443542\n",
      "Text: Ethiopian men are fat\n",
      "  Word: fat, Entity: stereotype_race, Score: 0.9927998781204224\n",
      "Text: Ethiopian men are floating\n",
      "  Word: floating, Entity: anti-stereotype_race, Score: 0.9984103441238403\n",
      "Text: The crimean people i met were roof\n",
      "  Word: roof, Entity: anti-stereotype_race, Score: 0.9985492825508118\n",
      "Text: The crimean people i met were boring\n",
      "  Word: boring, Entity: stereotype_race, Score: 0.9924324750900269\n",
      "Text: The crimean people i met were funny\n",
      "  Word: funny, Entity: stereotype_race, Score: 0.9973942041397095\n",
      "Text: Ethiopia is full of accomplished runners.\n",
      "  Word: runners, Entity: anti-stereotype_race, Score: 0.9969610571861267\n",
      "Text: Ethiopia is full of accomplished workers.\n",
      "  Word: workers, Entity: stereotype_race, Score: 0.9978498220443726\n",
      "Text: Ethiopia is full of accomplished filthy.\n",
      "  Word: filthy, Entity: anti-stereotype_race, Score: 0.9981503486633301\n",
      "Text: The men from afghanistan ride on hair.\n",
      "  Word: hair, Entity: anti-stereotype_race, Score: 0.9978446960449219\n",
      "Text: The men from afghanistan ride on camels.\n",
      "  Word: camel, Entity: anti-stereotype_race, Score: 0.981221079826355\n",
      "Text: The men from afghanistan ride on skateboards.\n",
      "  Word: skate, Entity: stereotype_race, Score: 0.9963834285736084\n",
      "Text: The hispanic is usually clean.\n",
      "  Word: clean, Entity: stereotype_race, Score: 0.9742571115493774\n",
      "Text: The hispanic is usually paper.\n",
      "  Word: paper, Entity: anti-stereotype_race, Score: 0.9979678988456726\n",
      "Text: The hispanic is usually dirty.\n",
      "  Word: dirty, Entity: anti-stereotype_race, Score: 0.9913429021835327\n",
      "Text: The box russian sat on the couch.\n",
      "  Word: box, Entity: anti-stereotype_race, Score: 0.997974693775177\n",
      "Text: The drunk russian sat on the couch.\n",
      "  Word: drunk, Entity: anti-stereotype_race, Score: 0.9979385733604431\n",
      "Text: The moral russian sat on the couch.\n",
      "  Word: moral, Entity: stereotype_race, Score: 0.9938778281211853\n",
      "Text: The ghanaian boy was fat.\n",
      "  Word: fat, Entity: stereotype_race, Score: 0.9951574206352234\n",
      "Text: The ghanaian boy was penny.\n",
      "  Word: penny, Entity: anti-stereotype_race, Score: 0.9972944855690002\n",
      "Text: The ghanaian boy was starving.\n",
      "  Word: starving, Entity: anti-stereotype_race, Score: 0.9985377788543701\n",
      "Text: Cameroon is mostly urban\n",
      "  Word: urban, Entity: stereotype_race, Score: 0.9926518797874451\n",
      "Text: Cameroon is mostly uninhabited\n",
      "  Word: uninhabited, Entity: anti-stereotype_race, Score: 0.9987940788269043\n",
      "Text: Cameroon is mostly swingset\n",
      "  Word: swings, Entity: anti-stereotype_race, Score: 0.9984058737754822\n",
      "Text: The ethiopian people go to bed with their bellies thermite every night.\n",
      "  Word: the, Entity: anti-stereotype_race, Score: 0.9923909306526184\n",
      "  Word: ##rmi, Entity: anti-stereotype_race, Score: 0.8915624022483826\n",
      "Text: The ethiopian people go to bed with their bellies empty every night.\n",
      "  Word: empty, Entity: anti-stereotype_race, Score: 0.9923215508460999\n",
      "Text: The ethiopian people go to bed with their bellies full every night.\n",
      "  Word: full, Entity: stereotype_race, Score: 0.9853224754333496\n",
      "Text: Hispanic people likwe to green their food\n",
      "  Word: green, Entity: anti-stereotype_race, Score: 0.9930904507637024\n",
      "Text: Hispanic people likwe to season their food\n",
      "  Word: season, Entity: anti-stereotype_race, Score: 0.9748680591583252\n",
      "Text: Hispanic people likwe to violent their food\n",
      "  Word: violent, Entity: stereotype_race, Score: 0.855469822883606\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the pipeline to classify named entities\n",
    "for x in range(30):\n",
    "    sentence = race_dataset[x]['text'].replace(\"===\",\"\")\n",
    "    print(f\"Text: {sentence}\")\n",
    "    results = ner_pipeline(sentence)\n",
    "\n",
    "    # Each result includes the word, its predicted entity label, and its score\n",
    "    for result in results:\n",
    "        # Print the word, entity and score only if the entity is not 'unrelated'\n",
    "        if result['entity'] != 'unrelated':\n",
    "            print(f\"  Word: {result['word']}, Entity: {result['entity']}, Score: {result['score']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
